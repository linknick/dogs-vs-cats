# -*- coding: utf-8 -*-
"""dogs-vs.-cats.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juBle521xjA4uai2F16x-Cc90Qmea06Y

下載資料集，這邊以kaggle上的https://www.kaggle.com/datasets/chetankv/dogs-cats-images 資料集為例子。
藉由kaggle提供的api_token可以將下載行為腳本化，無須手動操作。
"""

api_token = {}
import json
import zipfile
import os

if not os.path.exists("/root/.kaggle"):
    os.makedirs("/root/.kaggle")

with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)
!chmod 600 /root/.kaggle/kaggle.json

if not os.path.exists("/kaggle"):
    os.makedirs("/kaggle")
os.chdir('/kaggle')
!kaggle datasets download -d chetankv/dogs-cats-images --force

!ls /kaggle

"""將剛下載的資料集解壓縮，並放置到指定的資料夾中。"""

! unzip dogs-cats-images.zip -d dog-cats/

"""引入會使用的模組，常用的包括pandas, numpy, PIL, matplotlib, sklearn, keras"""

# Commented out IPython magic to ensure Python compatibility.
class color:
    BOLD = '\033[1m'
    BOLD_COLOR = '\033[1m' + '\033[93m'
    END = '\033[0m'



# loading libraries
print(color.BOLD + '\nImporting requreid libraries....\n'+ color.END)

import warnings
warnings.filterwarnings('ignore')

# basic librareis
import zipfile
import glob
import os
import pandas as pd
import numpy as np
from PIL import Image


# plotting and visualizations
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import missingno as msno

# preprocessing
from keras.preprocessing.image import (ImageDataGenerator,
                                       img_to_array,
                                       array_to_img,
                                       load_img)

from sklearn.model_selection import train_test_split

# metrics
from sklearn.metrics import (confusion_matrix,
                             classification_report,
                             accuracy_score,
                             f1_score,
                             roc_auc_score)
# modeling
import tensorflow as tf
from keras.models import Model,Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense,Flatten

from keras.applications import resnet50
from keras.applications.resnet50 import preprocess_input
from keras import optimizers
from keras import regularizers
from keras.callbacks import EarlyStopping,LearningRateScheduler


from keras import backend as K
K.clear_session()

# model plotting
from IPython.display import SVG
from tensorflow.keras.utils import model_to_dot
from keras.utils import plot_model

# mesc
from sklearn.utils import shuffle





print(color.BOLD_COLOR + 'Done!!!'+ color.END)

"""為了方便記錄模型的準確度、損失，以及將模型視覺化，引入好用的tensorboard工具，並設定log路徑。"""

# Commented out IPython magic to ensure Python compatibility.

# %load_ext tensorboard
!rm -rf ./logs/
import datetime
log_dir = "myLogs/Logs/" + datetime.datetime.now().strftime("%d-%m-%Y-%H%M%S") #You may add your own directory
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

"""將資料集分為訓練集與測試集，其中資料集可以分一部分為驗證集，可以更好的衡量神經網路模型的效能。"""

from pathlib import Path
originDir = ["dog-cats/dog vs cat/dataset/training_set/dogs","dog-cats/dog vs cat/dataset/training_set/cats"]
destinationDir = "training_set"
originDir2 = ["dog-cats/dog vs cat/dataset/test_set/dogs","dog-cats/dog vs cat/dataset/test_set/cats"]
destinationDir2 = "test_set"
if not os.path.exists(destinationDir):
	os.makedirs(destinationDir)

for dir in originDir:
	all_data = os.listdir(dir)
	num_all_data = len(all_data)
	index_list = list(range(num_all_data))
	for i in index_list:
		fileName = os.path.join(dir, all_data[i])
		desName = destinationDir+"/"+all_data[i]

		Path(fileName).rename(desName)

if not os.path.exists(destinationDir2):
	os.makedirs(destinationDir2)
for dir in originDir2:
	all_data = os.listdir(dir)
	num_all_data = len(all_data)
	index_list = list(range(num_all_data))
	for i in index_list:
		fileName = os.path.join(dir, all_data[i])
		desName = destinationDir2+"/"+all_data[i]

		Path(fileName).rename(desName)

"""設定訓練集與測試集的路徑，並顯示樣本個數。"""

# Total number of images in train and test datasets

train_dir = '/kaggle/training_set/'
test_dir  = '/kaggle/test_set/'
print(color.BOLD +"Total Images in Train, and Test Data..." +color.END)
print('\n' + color.BOLD_COLOR + 'No. of Train Images: '+ color.END + color.BOLD + str(len(os.listdir(train_dir))) + color.END)
print( color.BOLD_COLOR + 'No. of Test Images: ' + color.END + color.BOLD + str(len(os.listdir(test_dir))) + color.END + '\n')

"""將資料讀入程式，並顯示詳細資料。"""

train_data = os.listdir(train_dir)
d = []
for fileName in train_data:
  path = train_dir+fileName
  label = fileName[:3]
  #label = 0 if label=='cat' else 1
  d.append(
      {
          'path': path,
          'label':label
      }
  )
train_df = pd.DataFrame(d)
print(train_df)

test_data = os.listdir(test_dir)
d = []
for fileName in test_data:
  path = test_dir+fileName
  label = fileName[:3]
  #label = 0 if label=='cat' else 1
  d.append(
      {
          'path': path,
          'label':label
      }
  )
test_df = pd.DataFrame(d)
print(test_df)

"""設定一些訓練參數，將資料轉成可以被輸入神經網路的型態(ImageDataGenerator會將影像讀入並轉成 w x h x 3的numpy array)。"""

img_size = 224
batch_size = 128

print(color.BOLD_COLOR + '\nPreparing train and validation images for training...' + color.END)
# dataframe iterators without data agumnetation

train_map = ImageDataGenerator()
test_map =  ImageDataGenerator()

print(color.BOLD)

#Creatinga a dataframe iterators for fitting
vani_train_data = train_map.flow_from_dataframe(
            train_df,train_dir,
            x_col = 'path',
            y_col = 'label',
            target_size = (img_size, img_size),
            batch_size = batch_size,
            class_mode = 'categorical')

vani_test_data = test_map.flow_from_dataframe(
             test_df, train_dir,
             x_col = 'path',
             y_col = None,
             target_size = (img_size, img_size),
             batch_size = batch_size,
             class_mode = None,
             shuffle = False)

print(color.BOLD_COLOR + '\nDone!')

"""建立模型，這邊一共建立了五個小模塊，每個模塊包含兩個cnn層及一個pooling層，並在靠近輸出的兩個模塊後添加了dropout防止overfitting，最後用flatten轉成一維向量並透過兩層fully connect(DENSE)層輸出。"""

#Building model computational graph
vani_model = Sequential()
vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))
vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))

vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))

vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

vani_model.add(Dropout(0.3))

vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))
vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

vani_model.add(Dropout(0.3))

vani_model.add(Flatten())

vani_model.add(Dense(512, activation = 'relu'))

vani_model.add(Dropout(0.5))

vani_model.add(Dense(2, activation = 'softmax'))

print(color.BOLD_COLOR + '\nVanilla Model layers and output shapes with params...\n'+color.END)

print(color.BOLD)
vani_model.summary()

"""圖像化模型

"""

plot_model(vani_model, show_shapes = True,expand_nested = True,dpi = 80)
#SVG(model_to_dot(vani_model).create(prog='dot', format='svg'))

train_images = train_df.shape[0]
test_images = test_df.shape[0]
print(train_images,test_images)

"""設定訓練損失函數與optimizer"""

#compiling model with loss, opt, metrics
loss = 'categorical_crossentropy'
opt = tf.keras.optimizers.Adam(learning_rate= 0.0001,beta_1=0.9, beta_2=0.999,epsilon=1e-07)
metrics = ['accuracy']

"""訓練15個EPOCH(初步訓練)"""

vani_model.compile(loss = loss, optimizer = opt, metrics = metrics)

print(color.BOLD_COLOR + 'Training on Vanilla CNN has started ....\n'+ color.END)
print(color.BOLD)
# fitting the model for training dataset
vani_history = vani_model.fit(vani_train_data, epochs = 15,
                          steps_per_epoch= train_images//batch_size)

print(color.END)
print(color.BOLD_COLOR + '\nDone!\n'+ color.END)

"""將訓練好的模型套用到測試資料上"""

labels = dict((v,k) for k,v in vani_train_data.class_indices.items())
x_test_imgname = [file for file in os.listdir(test_dir)]
print(labels)

submission_image_df = pd.DataFrame({'filename': x_test_imgname})
vani_sub_aug_map = ImageDataGenerator()
vani_sub_data = vani_sub_aug_map.flow_from_dataframe(
             submission_image_df, test_dir,
             x_col = 'filename',
             y_col = None,
             class_mode = None,
             target_size = (img_size, img_size),
             shuffle = False)



vani_pred_sub = vani_model.predict_generator(vani_sub_data)
submission_image_df['vani_pred_sub'] = np.argmax(vani_pred_sub, axis = -1)
submission_image_df['vani_pred_sub'] = submission_image_df['vani_pred_sub'].map(labels)

res = [file.split(".")[0] for file in os.listdir(test_dir)]
df2 = pd.DataFrame({
    'filename':x_test_imgname,
    'res': res})
submission_image_df=pd.merge(left=submission_image_df,right=df2,how="inner")

print(submission_image_df)

"""算一下準確率"""

matched = submission_image_df[submission_image_df['vani_pred_sub']==submission_image_df['res']].shape[0]
print("Accuracy = ", matched /test_images * 100, "%")

"""訓練效果不太好，加入一些資料增強的小調整，對訓練資料進行隨機的旋轉/位移/縮放/水平翻轉"""

print(color.BOLD +'\n'+'Helper funtions for Image Agumentation visualizations' +'\n'+color.END)

def data_argumentation_show(n, grid_size):
    sample_aug_map = ImageDataGenerator(
            #zoom_range = 0.1,
            rotation_range = 25,
            horizontal_flip = True,
            height_shift_range =0.2,
            width_shift_range = 0.2,
            fill_mode='nearest',
            rescale = 1/255)
    sample_data = sample_aug_map.flow_from_dataframe(
            (train_df.sample(n)),
            train_dir,
            x_col = 'path',
            y_col = 'label',
            target_size = (img_size, img_size),
            class_mode = 'categorical')

  #subplot grid
    fig = plt.figure(figsize = (10,10))
    fig.patch.set_facecolor('#f5f6f6')
    for i in range(0,grid_size*grid_size):
        plt.subplot(grid_size,grid_size, i+1)
        for x,y in sample_data:
            img = x[0]
            plt.imshow(img)
            plt.axis('off')
            break
            plt.tight_layout()
            del img
    fig.show()


    fig.text(0.1,0.93, 'Hey Siri! is it cat or dog?: Image agumentation',{'fontfamily':'serif','size':20,'weight':'bold'})

    return None

data_argumentation_show(1, 5)

"""對學習率進行調整，使其會依照訓練次數慢慢衰減，避免梯度下降的步伐過大導致損失
無法下降。
"""

print(color.BOLD + '\nSetting a decay learning rate for learning rate schedule\n'+ color.END)
epoch = 50
learning_rate = 1e-4
lr_start = 1e-4
lr_min = 0.000001
lr_max = 1e-4
lr_rampup_epochs = 0
lr_sustain_epochs = 0
lr_exp_decay = .99

def lrfn(epoch):
    if epoch < lr_rampup_epochs:
        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start
    elif epoch < lr_rampup_epochs + lr_sustain_epochs:
        lr = lr_max
    else:
        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min
    return lr

print(color.BOLD_COLOR + 'Done!' +color.END)

"""顯示學習率的下降速率"""

epochs = 20
epochs_range = [i for i in range(50 if epochs<50 else epochs)]
learn_rate = [lrfn(x) for x in epochs_range]


fig,ax = plt.subplots(figsize = (10,5))
fig.patch.set_facecolor('#f5f6f6')
ax.set_facecolor('#f5f6f6')

for loc in ['right','top',]:
    ax.spines[loc].set_visible(False)

ax.plot(epochs_range, learn_rate, linewidth = 4, color= '#36609A')
plt.xlabel('Range of epochs',{'fontfamily':'serif', 'size':14,  'color':'black', 'weight':'bold'})
plt.ylabel('Learning rate in 10^-5',{'fontfamily':'serif', 'size':14,  'color':'black', 'weight':'bold'})


plt.gcf().text(0,1.06,'Learning Rate Schedule',{'fontfamily':'serif', 'size':24,  'color':'black', 'weight':'bold'})
plt.gcf().text(0,0.975,"""Initially set a learning rate that linearly increase from 1e-08 to 3e-5 and later
exponentially decreases from 3e-5 to 1e-6""",{'fontfamily':'serif', 'size':14,  'color':'black', })

plt.gcf().text(0.75,0,'© Made by bhuvanchennoju/Kaggle',{'fontfamily':'serif', 'size':10,  'color':'black'})
plt.gcf().show()

"""設定訓練參數"""

earlystop = EarlyStopping(patience= 5)

lr_callback = LearningRateScheduler(lrfn, verbose = True)
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)
callbacks = [earlystop, lr_callback, tensorboard_callback]

train_aug_map = ImageDataGenerator(
                    rotation_range=10,
                    zoom_range=0.1,
                    horizontal_flip=True,
                    fill_mode='nearest',
                    width_shift_range=0.1,
                    height_shift_range=0.1,
                    preprocessing_function = preprocess_input
                    )
res_train_data = train_aug_map.flow_from_dataframe(
            train_df, train_dir,
            x_col = 'path',
            y_col = 'label',
            target_size = (img_size, img_size),
            batch_size = batch_size,
            class_mode = 'categorical')

"""用一個新的模型看看改動後的效果"""

#Building model computational graph
my_model = Sequential()
my_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))
my_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same'))
my_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))

my_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))
my_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))
my_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))

my_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))
my_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))
my_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

my_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))
my_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))
my_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

my_model.add(Dropout(0.3))

my_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))
my_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))
my_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))

my_model.add(Dropout(0.3))

my_model.add(Flatten())

my_model.add(Dense(512, activation = 'relu'))

my_model.add(Dropout(0.5))

my_model.add(Dense(2, activation = 'softmax'))

#my_model.summary()
#compiling model with loss, opt, metrics
my_opt = tf.keras.optimizers.Adam(learning_rate= 0.0001,beta_1=0.9, beta_2=0.999,epsilon=1e-07)
my_model.compile(loss = 'categorical_crossentropy', optimizer = my_opt, metrics = metrics)

print(color.BOLD_COLOR + 'Training on My CNN has started ....\n'+ color.END)
print(color.BOLD)
# fitting the model for training dataset
my_history = my_model.fit(res_train_data, epochs = 15,
                          steps_per_epoch= train_images//batch_size,
                          callbacks = callbacks)

print(color.END)
print(color.BOLD_COLOR + '\nDone!\n'+ color.END)

"""因為每次會隨機進行資料增強，可以看到訓練時間變久了。學習率也會隨批次慢慢衰減。

現在將新模型套用至測試資料。
"""

labels = dict((v,k) for k,v in res_train_data.class_indices.items())
x_test_imgname = [file for file in os.listdir(test_dir)]
print(labels)

submission_image_df = pd.DataFrame({'filename': x_test_imgname})
my_sub_aug_map = ImageDataGenerator()
my_sub_data = vani_sub_aug_map.flow_from_dataframe(
             submission_image_df, test_dir,
             x_col = 'filename',
             y_col = None,
             class_mode = None,
             target_size = (img_size, img_size),
             shuffle = False)



my_pred_sub = my_model.predict_generator(my_sub_data)
#my_pred_sub = vani_model.predict_generator(my_sub_data)
submission_image_df['my_pred_sub'] = np.argmax(my_pred_sub, axis = -1)
submission_image_df['my_pred_sub'] = submission_image_df['my_pred_sub'].map(labels)

res = [file.split(".")[0] for file in os.listdir(test_dir)]
df2 = pd.DataFrame({
    'filename':x_test_imgname,
    'res': res})
submission_image_df=pd.merge(left=submission_image_df,right=df2,how="inner")

print(submission_image_df)
matched = submission_image_df[submission_image_df['my_pred_sub']==submission_image_df['res']].shape[0]
print("Accuracy = ", matched /test_images * 100, "%")

"""顯示tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir myLogs/Logs

from tensorboard import notebook
notebook.list()

notebook.display(port=6006, height=1000)

"""將模型、預測結果儲存成檔案"""

from google.colab import files
submission_image_df.to_csv('output.csv', encoding = 'utf-8-sig',index=False)
my_model.save('location.keras')
#files.download('output.csv')
#files.download('location.keras')

resNet = tf.keras.applications.ResNet50(weights = 'imagenet',
                        include_top = False,
                        input_shape = (224,224, 3))

resNet.trainable = False # Freeze layers
resNet_model = Sequential([
        resNet,
        Flatten(),
        Dense(1024, activation = 'relu'),
        Dropout(0.4),
        Dense(2, activation = 'softmax')])


optimizer = optimizers.Adam(1e-5)

print(color.BOLD_COLOR + '\nResNet based Transfer learning Model layers and output shapes with params...\n'+color.END)

print(color.BOLD)
resNet_model.summary()

resNet_model.compile(optimizer = optimizer,
             loss = 'categorical_crossentropy',
             metrics = ['accuracy'])

print(color.BOLD_COLOR + 'Training on ResNet50 has started ....\n'+ color.END)
print(color.BOLD)

resnet_history = resNet_model.fit_generator(res_train_data, epochs = 3,
                          steps_per_epoch= train_images//batch_size,
                          callbacks = callbacks)
print(color.END)
print(color.BOLD_COLOR + 'Done!\n'+ color.END)